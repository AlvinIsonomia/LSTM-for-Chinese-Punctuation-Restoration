{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/home/data/liuchang/anaconda3/envs/py3/bin/python\n",
    "# -*- coding:utf-8 -*-\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os \n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')# 忽略警告\n",
    "import logging\n",
    "import os.path\n",
    "import sys\n",
    "import multiprocessing\n",
    "import gensim    \n",
    "import torch\n",
    "from torch.utils.data import *\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd\n",
    "# xlist = np.load('/home/data/liuchang/data/wikiw2v.npy') \n",
    "# ylist = np.load('/home/data/liuchang/data/wikipunc.npy') \n",
    "# del xlist\n",
    "# del ylist\n",
    "# gc.collect()\n",
    "\n",
    "# dataloader\n",
    "# batch_size = 1\n",
    "# class wikiset(Dataset):\n",
    "#     def __init__(self):\n",
    "#         print('dataset loading...')\n",
    "#         self.xlist = np.load('/home/data/liuchang/data/wikiw2v.npy') \n",
    "#         self.ylist = np.load('/home/data/liuchang/data/wikipunc.npy') \n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.ylist)\n",
    "#     def __getitem__(self,idx):\n",
    "#         return torch.FloatTensor(self.xlist[idx]),torch.FloatTensor(self.ylist[idx])\n",
    "\n",
    "# teset = wikiset()        \n",
    "# seqloader = DataLoader(teset,batch_size=1,shuffle = False ,num_workers = 4)            \n",
    "\n",
    "class TLSTM(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_dim,output_dim):\n",
    "        super(TLSTM,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1,1,self.hidden_dim),torch.zeros(1,1,self.hidden_dim)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        lstm_out, self.hidden = self.lstm(inputs.view(len(inputs),1,-1),self.hidden)\n",
    "        tag_space = self.fc(lstm_out.view(len(inputs),-1))\n",
    "        tag_scores = F.softmax(tag_space,dim = 1)\n",
    "        return tag_scores\n",
    "lstm = TLSTM(200,100,6)\n",
    "model = gensim.models.Word2Vec.load('/home/data/liuchang/data/Tinywikizh.model')\n",
    "lstm.load_state_dict(torch.load('tlstm.pkl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_punc(sentence):\n",
    "    senseg = ' '.join(jieba.cut(sentence,cut_all=False))\n",
    "    print(senseg)\n",
    "    zerovec = np.zeros(200)\n",
    "    xpara = []\n",
    "    for word in senseg.split():\n",
    "        try:\n",
    "            xpara.append(model[word])\n",
    "        except:\n",
    "            xpara.append(zerovec)\n",
    "            # torch.load(lstm.state_dict(), 'tlstm.pkl')\n",
    "    x = torch.FloatTensor(xpara)\n",
    "    with torch.no_grad():\n",
    "        lstm.hidden = lstm.init_hidden()\n",
    "        tag_scores = lstm(x)\n",
    "    # y = lstm(xpara[0])\n",
    "    print('raw sentence:',sentence)\n",
    "    a,index = torch.max(tag_scores,dim = 1) \n",
    "    print('punc index:',index)\n",
    "    punc_dict = {0:'',1:'，',2:'。',3:'！',4:'？',5:'、'}\n",
    "    word = senseg.split()\n",
    "    puncsen = ''\n",
    "    for i in range(0,len(tag_scores)):\n",
    "        puncsen += word[i]+punc_dict[int(index[i])]\n",
    "    print('cyberpuncor result:',puncsen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 2.185 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/home/data/liuchang/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于 长短期 记忆 神经网络 的 标点 恢复 模型 是 真 他妈的 好用 啊\n",
      "raw sentence: 基于长短期记忆神经网络的标点恢复模型是真他妈的好用啊\n",
      "punc index: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3])\n",
      "cyberpuncor result: 基于长短期记忆神经网络的标点，恢复模型是真他妈的好用啊！\n",
      "3.95646333694458\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import jieba\n",
    "tic = time.time()\n",
    "print_punc('基于长短期记忆神经网络的标点恢复模型是真他妈的好用啊')\n",
    "print(time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基于 长短期 记忆 神经网络 的 标点 恢复 模型 是 真 他妈的 好用 啊\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/data/liuchang/anaconda3/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw sentence: 基于长短期记忆神经网络的标点恢复模型是真他妈的好用啊\n",
      "punc index: tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 3])\n",
      "cyberpuncor result: 基于长短期记忆神经网络的标点恢复模型，是真他妈的好用啊！\n",
      "1.9918181896209717\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = '哈哈哈哈我现在在找各种各样乱七八糟的文本丢到这个破网络里看看结果咋样'\n",
    "print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
